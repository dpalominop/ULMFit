{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "# !conda install gensim -y\n",
    "# !conda install nltk -y\n",
    "import lib.xmlreader as xml\n",
    "import lib.utils as ut\n",
    "import numpy as np\n",
    "\n",
    "import gensim.models.word2vec\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Getting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import os\n",
    "# sys.path.insert(0, os.getcwd()+'/fastai/')\n",
    "sys.path.insert(0, os.getcwd()+'/ELMoForManyLangs/')\n",
    "from fastai.text import *\n",
    "import html\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "\n",
    "np.random.seed(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "YEAR='2017'\n",
    "DATA_PATH=Path('./DATA/'+YEAR)\n",
    "# DATA_PATH=Path('./data/election_tweets')\n",
    "\n",
    "WIKILM_PATH=Path('./WIKI_LM/es/models')\n",
    "PRE_FINETUNE_PATH=Path('./FINETUNE/'+YEAR)\n",
    "\n",
    "TWEETSLM_PATH=Path('./TWEETS_LM/'+YEAR)\n",
    "CLAS_PATH=Path('./TWEETS_CLAS/'+YEAR)\n",
    "\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flattern(A):\n",
    "    'Source: https://stackoverflow.com/a/17867797/7273299'\n",
    "    \n",
    "    'Flattens a list of lists and strings into a list.'\n",
    "    rt = []\n",
    "    for i in A:\n",
    "        if isinstance(i,list): rt.extend(flattern(i))\n",
    "        else: rt.append(i)\n",
    "    return rt\n",
    "\n",
    "def isInt(v):\n",
    "    'Source: https://stackoverflow.com/a/9859202/7273299'\n",
    "    \n",
    "    'Checks if a string is a number.'\n",
    "    try:     i = int(v)\n",
    "    except:  return False\n",
    "    return True\n",
    "\n",
    "def char_count(word, chars, lbound=2):\n",
    "    char_count = [word.count(char) for char in chars]\n",
    "    return all(i >= lbound for i in char_count)\n",
    "\n",
    "def replace_lol(repl_str, texts):\n",
    "    for string, chars in repl_str:\n",
    "        texts = [[[string] if char_count(i, set(chars), 2) else i for i in text.split()] for text in texts]\n",
    "        texts = np.array([flattern(text) for text in texts])\n",
    "        texts = np.array([' '.join(text) for text in texts])\n",
    "    return texts\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "def strip_accents(text):\n",
    "    \"\"\"\n",
    "    Strip accents from input String.\n",
    "\n",
    "    :param text: The input string.\n",
    "    :type text: String.\n",
    "\n",
    "    :returns: The processed String.\n",
    "    :rtype: String.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        text = unicode(text, 'utf-8')\n",
    "    except (TypeError, NameError): # unicode is a default on python 3 \n",
    "        pass\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    text = text.encode('ascii', 'ignore')\n",
    "    text = text.decode(\"utf-8\")\n",
    "    return str(text)\n",
    "\n",
    "def preprocess_tweets(tweets):\n",
    "    \"\"\"\n",
    "    twitter specific text processing and shuffle\n",
    "    \"\"\"\n",
    "    # Remove \\n\n",
    "    tweets = np.array([str(i).replace('\\n','. ') for i in tweets])\n",
    "    tweets = np.array([str(i).replace('&lt;',' ') for i in tweets])\n",
    "    tweets = np.array([str(i).replace('&gt;',' ') for i in tweets])\n",
    "    tweets = np.array([str(i).replace('\\xa0',' ') for i in tweets])\n",
    "    \n",
    "    # Remove accents\n",
    "    tweets = np.array([strip_accents(i) for i in tweets])\n",
    "    \n",
    "    # Placeholders for hyperlinks and user references\n",
    "    tweets = [['hyp_link' if i.startswith('http') \n",
    "               else 'hyp_link' if i.startswith('.http') \n",
    "               else 'user_ref' if i.startswith('@')\n",
    "               else 'hash_tag' if i.startswith('#')\n",
    "               else i for i in tweet.split()] for tweet in tweets]\n",
    "    tweets = np.array([' '.join(i) for i in tweets])\n",
    "\n",
    "    # Prefix for integers\n",
    "    tweets = [[['int_string'] if isInt(i) \n",
    "               else i for i in tweet.split()] for tweet in tweets]\n",
    "    tweets = np.array([flattern(tweet) for tweet in tweets])\n",
    "    tweets = np.array([' '.join(i) for i in tweets])\n",
    "\n",
    "    # Prefix for slang\n",
    "    tweets = [[['que'] if i in ['q', 'k', 'qu', 'ke', 'qe'] \n",
    "               else ['por'] if i=='x' \n",
    "               else ['porque'] if i in ['xq', 'pq', 'porq'] \n",
    "               else ['de'] if i=='d' \n",
    "               else ['te'] if i=='t'\n",
    "               else ['también'] if i=='tb'\n",
    "               else ['Que'] if i in ['Q', 'K', 'Qu','Ke', 'Qe'] \n",
    "               else ['Por'] if i=='X'\n",
    "               else ['Porque'] if i in ['Xq', 'Pq', 'Porq'] \n",
    "               else ['De'] if i=='D' \n",
    "               else ['Te'] if i=='T'\n",
    "               else ['También'] if i=='Tb'\n",
    "               else i for i in tweet.split()] for tweet in tweets]\n",
    "    tweets = np.array([flattern(tweet) for tweet in tweets])\n",
    "    tweets = np.array([' '.join(i) for i in tweets])\n",
    "\n",
    "    # Lol type characters\n",
    "    repl_str = [('risa_ja','ja'), ('risa_ji','ji'), ('risa_je','je'), ('risa_jo','jo'), ('risa_ju', 'ju'),\n",
    "               ('risa_ja','aj'), ('risa_ji','ij'), ('risa_ju', 'uj'), ('risa_ja', 'lol')]\n",
    "\n",
    "    # Adding prefix to lol type characters\n",
    "    tweets = replace_lol(repl_str, tweets)\n",
    "\n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download es\n",
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n",
    "\n",
    "def get_texts(df):\n",
    "    labels = df[0].values.astype(np.int64)\n",
    "    texts = f'{BOS} ' + df[1].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    tok = Tokenizer(lang='es').proc_all_mp(partition_by_cores(texts), lang='es')\n",
    "    return tok, list(labels)\n",
    "\n",
    "def get_all(df):\n",
    "    tok, labels = [], []\n",
    "    tok_, labels_ = get_texts(df)\n",
    "    tok += tok_;\n",
    "    labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-06-19 18:17:42,668 INFO: char embedding size: 2637\n",
      "2019-06-19 18:17:43,336 INFO: word embedding size: 185214\n",
      "2019-06-19 18:17:46,850 INFO: Model(\n",
      "  (token_embedder): ConvTokenEmbedder(\n",
      "    (word_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(185214, 100, padding_idx=3)\n",
      "    )\n",
      "    (char_emb_layer): EmbeddingLayer(\n",
      "      (embedding): Embedding(2637, 50, padding_idx=2634)\n",
      "    )\n",
      "    (convolutions): ModuleList(\n",
      "      (0): Conv1d(50, 32, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(50, 32, kernel_size=(2,), stride=(1,))\n",
      "      (2): Conv1d(50, 64, kernel_size=(3,), stride=(1,))\n",
      "      (3): Conv1d(50, 128, kernel_size=(4,), stride=(1,))\n",
      "      (4): Conv1d(50, 256, kernel_size=(5,), stride=(1,))\n",
      "      (5): Conv1d(50, 512, kernel_size=(6,), stride=(1,))\n",
      "      (6): Conv1d(50, 1024, kernel_size=(7,), stride=(1,))\n",
      "    )\n",
      "    (highways): Highway(\n",
      "      (_layers): ModuleList(\n",
      "        (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "        (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (projection): Linear(in_features=2148, out_features=512, bias=True)\n",
      "  )\n",
      "  (encoder): ElmobiLm(\n",
      "    (forward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_0): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (forward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "    (backward_layer_1): LstmCellWithProjection(\n",
      "      (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
      "      (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
      "      (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# !pip install overrides\n",
    "from elmoformanylangs import Embedder\n",
    "e = Embedder('./145')\n",
    "# elmo = pickle.load((Path('./145')/'encoder.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = e.sents2elmo([['hola','comos', 'vas']])\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e.sents2elmo([['como']])[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(DATA_PATH/'train.csv', header=None)\n",
    "df_val = pd.read_csv(DATA_PATH/'validation.csv', header=None)\n",
    "df_tst = pd.read_csv(DATA_PATH/'test.csv', header=None)\n",
    "df_gen = pd.read_csv(DATA_PATH/'general.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3,\n",
       "        '-Me caes muy bien \\n-Tienes que jugar más partidas al lol con Russel y conmigo\\n-Por qué tan Otako, deja de ser otako\\n-Haber si me muero'],\n",
       "       [0,\n",
       "        '@myendlesshazza a. que puto mal escribo\\n\\nb. me sigo surrando help \\n\\n3. ha quedado raro el \"cómetelo\" ahí JAJAJAJA'],\n",
       "       [0, '@estherct209 jajajaja la tuya y la d mucha gente seguro!! Pero yo no puedo sin mi melena me muero '],\n",
       "       [1, 'Quiero mogollón a @AlbaBenito99 pero sobretodo por lo rápido que contesta a los wasaps '],\n",
       "       [0, 'Vale he visto la tia bebiendose su regla y me hs dado muchs grima ']], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_trn = np.concatenate([df_trn.values]) #, df_gen.values]) #df_gen[df_gen[0]==2].values, df_gen[df_gen[0]==3].values]) #, df_gen.values])\n",
    "tweets_val = np.concatenate([df_val.values])\n",
    "tweets_tst = np.concatenate([df_tst.values])\n",
    "del df_trn, df_val, df_tst, df_gen\n",
    "\n",
    "tweets_trn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_trn[:,1] = preprocess_tweets(tweets_trn[:,1])\n",
    "tweets_val[:,1] = preprocess_tweets(tweets_val[:,1])\n",
    "tweets_tst[:,1] = preprocess_tweets(tweets_tst[:,1])\n",
    "\n",
    "corpus = np.concatenate([tweets_trn[:,1], tweets_val[:,1], tweets_tst[:,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['label', 'tweet']\n",
    "\n",
    "df_trn = pd.DataFrame({'tweet':tweets_trn[:,1], 'label':tweets_trn[:,0]}, columns=col_names)\n",
    "df_val = pd.DataFrame({'tweet':tweets_val[:,1], 'label':tweets_val[:,0]}, columns=col_names)\n",
    "df_tst = pd.DataFrame({'tweet':tweets_tst[:,1], 'label':tweets_tst[:,0]}, columns=col_names)\n",
    "\n",
    "del tweets_trn, tweets_val, tweets_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_trn['label'].value_counts())\n",
    "print(df_val['label'].value_counts())\n",
    "print(df_tst['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df(df):\n",
    "    lst = [df]\n",
    "    max_size = df['label'].value_counts().max()\n",
    "    for class_index, group in df.groupby('label'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    df = pd.concat(lst)\n",
    "    return df\n",
    "\n",
    "df_trn = balance_df(df_trn)\n",
    "# df_val = balance_df(df_val)\n",
    "\n",
    "print(df_trn['label'].value_counts())\n",
    "print(df_val['label'].value_counts())\n",
    "print(df_tst['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'validation.csv', header=False, index=False)\n",
    "df_tst.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
    "df_trn.shape, df_val.shape\n",
    "\n",
    "del df_trn, df_val, df_tst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None)\n",
    "df_val = pd.read_csv(CLAS_PATH/'validation.csv', header=None)\n",
    "df_tst = pd.read_csv(CLAS_PATH/'test.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn)\n",
    "tok_val, val_labels = get_all(df_val)\n",
    "tok_tst, tst_labels = get_all(df_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_tst.npy', tok_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)\n",
    "# np.save(CLAS_PATH/'tmp'/'tst_labels.npy', tst_labels)\n",
    "\n",
    "# df = pd.read_csv(CLAS_PATH/'test_labels.csv')\n",
    "# df['label']=df['label'].replace(['N','P','NEU','NONE'],[0,1,2,3])\n",
    "# np.save(CLAS_PATH/'tmp'/'tst_labels.npy', df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')\n",
    "tok_tst = np.load(CLAS_PATH/'tmp'/'tok_tst.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = pickle.load((TWEETSLM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])\n",
    "tst_clas = np.array([[stoi[o] for o in p] for p in tok_tst])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'tst_ids.npy', tst_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokens and Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')\n",
    "tst_clas = np.load(CLAS_PATH/'tmp/tst_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "# val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))\n",
    "tst_labels = np.load(CLAS_PATH/'tmp/tst_labels.npy').flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = pickle.load((TWEETSLM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trn_clas.shape)\n",
    "print(val_clas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trn_clas[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE_MODEL = TWEETSLM_PATH/'models/lm3_wgts.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(BACKBONE_MODEL, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = to_np(wgts['0.encoder.weight'])\n",
    "row_m = embedding_matrix.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(embedding_matrix.shape)\n",
    "print(wgts['1.decoder.weight'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate Vocabulary Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = CountVectorizer(tokenizer=ut.tokenizer, min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3413, 9153)\n"
     ]
    }
   ],
   "source": [
    "X = counter.fit_transform(corpus)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts = np.sum(X, axis=0).tolist()\n",
    "counts = sorted(counts[0], reverse=True)\n",
    "plt.plot(np.arange(len(counts)), counts)\n",
    "plt.title(\"word count distribution in corpus\")\n",
    "plt.ylabel(\"counts\")\n",
    "plt.xlabel(\"words\")\n",
    "acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Baseline Embedding (BoW)\n",
    "\n",
    "<a href=\"https://www.codecogs.com/eqnedit.php?latex=v_s&space;=&space;\\frac{1}{\\left&space;\\|&space;S&space;\\right&space;\\|}&space;\\sum_{w&space;\\in&space;S}&space;v_w\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?v_s&space;=&space;\\frac{1}{\\left&space;\\|&space;S&space;\\right&space;\\|}&space;\\sum_{w&space;\\in&space;S}&space;v_w\" title=\"v_s = \\frac{1}{\\left \\| S \\right \\|} \\sum_{w \\in S} v_w\" /></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3413, 9153)\n"
     ]
    }
   ],
   "source": [
    "# VOCAB_SIZE = 3000\n",
    "VOCAB_SIZE = X.shape[1]\n",
    "# counter = CountVectorizer(strip_accents=\"unicode\", max_features=VOCAB_SIZE)\n",
    "# counter = CountVectorizer(max_features=VOCAB_SIZE, tokenizer=ut.tokenizer)\n",
    "\n",
    "caption_texts = corpus\n",
    "Xc = counter.fit_transform(caption_texts).todense().astype(\"float\")\n",
    "print(Xc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3413, 1)\n"
     ]
    }
   ],
   "source": [
    "sent_lens = np.sum(Xc, axis=1).astype(\"float\")\n",
    "sent_lens[sent_lens == 0] = 1e-14\n",
    "print(sent_lens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E = np.zeros((VOCAB_SIZE, 1024))\n",
    "for word in counter.vocabulary_.keys():\n",
    "    try:\n",
    "        i = counter.vocabulary_[word]\n",
    "#         E[i] = embedding_matrix[stoi[word]] \n",
    "        E[i] = e.sents2elmo([[word]])[0].reshape(-1);\n",
    "    except KeyError:\n",
    "        pass\n",
    "    \n",
    "E[counter.vocabulary_['muchas']] = np.randn(1024)\n",
    "E[counter.vocabulary_['gracias']] = np.randn(1024)\n",
    "print(E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3413, 1024)\n"
     ]
    }
   ],
   "source": [
    "Xb = np.divide(np.dot(Xc, E), sent_lens)\n",
    "print(Xb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1514, 1024) (1514,) (506, 1024) (506,) (1899, 1024) (1899,)\n"
     ]
    }
   ],
   "source": [
    "tst_labels = np.load(CLAS_PATH/'tmp/tst_labels.npy').flatten()\n",
    "Xtrain, Xval, Xtest = Xb[0:(len(tweets_trn[:,1])+len(tweets_val[:,1]))], Xb[len(tweets_trn[:,1]):(len(tweets_trn[:,1])+len(tweets_val[:,1]))], Xb[(len(tweets_trn[:,1])+len(tweets_val[:,1])):]\n",
    "ytrain, yval, ytest = np.concatenate([tweets_trn[:,0], tweets_val[:,0]]).astype('int'), np.array(tweets_val[:,0]).astype('int'), tst_labels.astype('int')\n",
    "print(Xtrain.shape, ytrain.shape, Xval.shape, yval.shape, Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(Xtrain, ytrain, clf):\n",
    "    best_clf = None\n",
    "    best_score = 0.0\n",
    "    num_folds = 0\n",
    "    cv_scores = []\n",
    "    kfold = KFold(n_splits=10)\n",
    "    for train, val in kfold.split(Xtrain):\n",
    "        Xctrain, Xctest, yctrain, yctest = Xtrain[train], Xtrain[val], ytrain[train], ytrain[val]\n",
    "#         clf.fit(np.concatenate((Xctrain, Xctest), axis=0), np.concatenate((yctrain, yctest), axis=0))\n",
    "        clf.fit(Xctrain, yctrain)\n",
    "        # clf.fit(Xctrain, yctrain)\n",
    "        ytest_ = clf.predict(Xctest)\n",
    "        score = f1_score(yctest, ytest_, average='macro')\n",
    "#         score = clf.score(Xctest, yctest)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_clf = clf\n",
    "        print(\"fold {:d}, score: {:.3f}\".format(num_folds, score))\n",
    "        cv_scores.append(score)\n",
    "        num_folds += 1\n",
    "    return best_clf, cv_scores\n",
    "\n",
    "def test_eval(Xtest, ytest, clf):\n",
    "    print(\"===\")\n",
    "    print(\"Test set results\")\n",
    "    ytest_ = clf.predict(Xtest)\n",
    "    accuracy = accuracy_score(ytest, ytest_)\n",
    "    acc.append(accuracy)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    print(\"---\")\n",
    "    print(\"F1-M: {:.3f}\".format(f1_score(ytest, ytest_, average='macro')))\n",
    "    print(\"---\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    cm = confusion_matrix(ytest, ytest_)\n",
    "    print(cm)\n",
    "    print(\"---\")\n",
    "    print(\"Classification Report\")\n",
    "    cr = classification_report(ytest, ytest_)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, score: 0.418\n",
      "fold 1, score: 0.415\n",
      "fold 2, score: 0.401\n",
      "fold 3, score: 0.400\n",
      "fold 4, score: 0.372\n",
      "fold 5, score: 0.403\n",
      "fold 6, score: 0.360\n",
      "fold 7, score: 0.363\n",
      "fold 8, score: 0.382\n",
      "fold 9, score: 0.393\n",
      "===\n",
      "Test set results\n",
      "Accuracy: 0.434\n",
      "---\n",
      "F1-M: 0.376\n",
      "---\n",
      "Confusion Matrix\n",
      "[[423  75 118 151]\n",
      " [179 229  67 167]\n",
      " [ 93  33  34  56]\n",
      " [ 64  35  36 139]]\n",
      "---\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.55       767\n",
      "           1       0.62      0.36      0.45       642\n",
      "           2       0.13      0.16      0.14       216\n",
      "           3       0.27      0.51      0.35       274\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      1899\n",
      "   macro avg       0.39      0.39      0.38      1899\n",
      "weighted avg       0.49      0.43      0.44      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "clf = GaussianNB()\n",
    "best_clf, scores_nb = cross_val(Xtrain, ytrain, clf)\n",
    "# clf.fit(Xtrain, ytrain.astype('int'))\n",
    "test_eval(Xtest, ytest, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, score: 0.406\n",
      "fold 1, score: 0.396\n",
      "fold 2, score: 0.404\n",
      "fold 3, score: 0.392\n",
      "fold 4, score: 0.437\n",
      "fold 5, score: 0.383\n",
      "fold 6, score: 0.424\n",
      "fold 7, score: 0.346\n",
      "fold 8, score: 0.268\n",
      "fold 9, score: 0.434\n",
      "===\n",
      "Test set results\n",
      "Accuracy: 0.511\n",
      "---\n",
      "F1-M: 0.396\n",
      "---\n",
      "Confusion Matrix\n",
      "[[513 119  88  47]\n",
      " [191 376  38  37]\n",
      " [104  55  34  23]\n",
      " [118  84  25  47]]\n",
      "---\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.61       767\n",
      "           1       0.59      0.59      0.59       642\n",
      "           2       0.18      0.16      0.17       216\n",
      "           3       0.31      0.17      0.22       274\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      1899\n",
      "   macro avg       0.41      0.40      0.40      1899\n",
      "weighted avg       0.49      0.51      0.49      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', C=0.8)\n",
    "best_clf, scores_svc = cross_val(Xtrain, ytrain, clf)\n",
    "test_eval(Xtest, ytest, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7369758560388109"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score(clf.predict(Xval), np.array(yval), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(num):\n",
    "    if num == 0:\n",
    "        return 'N'\n",
    "    elif num == 1:\n",
    "        return 'P'\n",
    "    elif num == 2:\n",
    "        return 'NEU'\n",
    "    elif num == 3:\n",
    "        return 'NONE'\n",
    "    \n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def putTestValue(xmlFIle, out):\n",
    "    tree = ET.parse(xmlFIle)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    tweets = []\n",
    "    file = open(out,\"w\") \n",
    "    print(len(test_values))\n",
    "    for i,tweet in enumerate(root.iter('tweet')): \n",
    "        #print(i)\n",
    "        val = getLabel(test_values[i])\n",
    "        ID = tweet.find('tweetid').text\n",
    "        file.write(ID + \"\\t\" + val + \"\\n\")\n",
    "    file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "putTestValue(\"../database/TASS/TASS2018/task1-Test.xml\", \"output2018-2.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth Inverse Frequency (SIF) Embedding\n",
    "\n",
    "<a href=\"https://www.codecogs.com/eqnedit.php?latex=v_s&space;=&space;\\frac{1}{\\left&space;\\|&space;S&space;\\right&space;\\|}&space;\\sum_{w&space;\\in&space;S}&space;\\frac{\\alpha}{\\alpha&space;&plus;&space;p_w}&space;v_w\" target=\"_blank\"><img src=\"https://latex.codecogs.com/gif.latex?v_s&space;=&space;\\frac{1}{\\left&space;\\|&space;S&space;\\right&space;\\|}&space;\\sum_{w&space;\\in&space;S}&space;\\frac{\\alpha}{\\alpha&space;&plus;&space;p_w}&space;v_w\" title=\"v_s = \\frac{1}{\\left \\| S \\right \\|} \\sum_{w \\in S} \\frac{\\alpha}{\\alpha + p_w} v_w\" /></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from paper\n",
    "ALPHA = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # compute word probabilities from corpus\n",
    "freqs = np.sum(Xc, axis=0).astype(\"float\")\n",
    "probs = freqs / np.sum(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute multiplier ALPHA / (ALPHA + probs)\n",
    "coeff = ALPHA / (ALPHA + probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weighted counts\n",
    "Xw = np.multiply(Xc, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3413, 9153) (1, 9153) (3413, 1024) (9153, 1024)\n"
     ]
    }
   ],
   "source": [
    "# convert to SIF embeddings\n",
    "Xs = np.divide(np.dot(Xw, E), sent_lens)\n",
    "\n",
    "print(Xc.shape, coeff.shape, Xs.shape, E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1024) [0.094402]\n"
     ]
    }
   ],
   "source": [
    "# compute 1st principal component\n",
    "svd = TruncatedSVD(n_components=1, n_iter=20, random_state=0)\n",
    "svd.fit(Xs)\n",
    "pc = svd.components_\n",
    "print(pc.shape, svd.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3413, 1024)\n"
     ]
    }
   ],
   "source": [
    "# remove it from the weighted counts\n",
    "Xr = Xs - Xs.dot(pc.T).dot(pc)\n",
    "print(Xr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1514, 1024) (1514,) (506, 1024) (506,) (1899, 1024) (1899,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xval, Xtest = Xb[0:(len(tweets_trn[:,1])+len(tweets_val[:,1]))], Xb[len(tweets_trn[:,1]):(len(tweets_trn[:,1])+len(tweets_val[:,1]))], Xb[(len(tweets_trn[:,1])+len(tweets_val[:,1])):]\n",
    "ytrain, yval, ytest = np.concatenate([tweets_trn[:,0], tweets_val[:,0]]).astype('int'), np.array(tweets_val[:,0]).astype('int'), tst_labels.astype('int')\n",
    "print(Xtrain.shape, ytrain.shape, Xval.shape, yval.shape, Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, score: 0.418\n",
      "fold 1, score: 0.415\n",
      "fold 2, score: 0.401\n",
      "fold 3, score: 0.400\n",
      "fold 4, score: 0.372\n",
      "fold 5, score: 0.403\n",
      "fold 6, score: 0.360\n",
      "fold 7, score: 0.363\n",
      "fold 8, score: 0.382\n",
      "fold 9, score: 0.393\n",
      "===\n",
      "Test set results\n",
      "Accuracy: 0.434\n",
      "---\n",
      "F1-M: 0.376\n",
      "---\n",
      "Confusion Matrix\n",
      "[[423  75 118 151]\n",
      " [179 229  67 167]\n",
      " [ 93  33  34  56]\n",
      " [ 64  35  36 139]]\n",
      "---\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.55      0.55       767\n",
      "           1       0.62      0.36      0.45       642\n",
      "           2       0.13      0.16      0.14       216\n",
      "           3       0.27      0.51      0.35       274\n",
      "\n",
      "   micro avg       0.43      0.43      0.43      1899\n",
      "   macro avg       0.39      0.39      0.38      1899\n",
      "weighted avg       0.49      0.43      0.44      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "best_clf, scores_nb = cross_val(Xtrain, ytrain, clf)\n",
    "test_eval(Xtest, ytest, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0, score: 0.406\n",
      "fold 1, score: 0.396\n",
      "fold 2, score: 0.404\n",
      "fold 3, score: 0.392\n",
      "fold 4, score: 0.437\n",
      "fold 5, score: 0.383\n",
      "fold 6, score: 0.424\n",
      "fold 7, score: 0.346\n",
      "fold 8, score: 0.268\n",
      "fold 9, score: 0.434\n",
      "===\n",
      "Test set results\n",
      "Accuracy: 0.511\n",
      "---\n",
      "F1-M: 0.396\n",
      "---\n",
      "Confusion Matrix\n",
      "[[513 119  88  47]\n",
      " [191 376  38  37]\n",
      " [104  55  34  23]\n",
      " [118  84  25  47]]\n",
      "---\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.61       767\n",
      "           1       0.59      0.59      0.59       642\n",
      "           2       0.18      0.16      0.17       216\n",
      "           3       0.31      0.17      0.22       274\n",
      "\n",
      "   micro avg       0.51      0.51      0.51      1899\n",
      "   macro avg       0.41      0.40      0.40      1899\n",
      "weighted avg       0.49      0.51      0.49      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', C=0.8, gamma='scale')\n",
    "best_clf, scores_svc = cross_val(Xtrain, ytrain, clf)\n",
    "test_eval(Xtest, ytest, best_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=11, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=11, gamma='scale')\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "Test set results\n",
      "Accuracy: 0.491\n",
      "---\n",
      "F1-M: 0.396\n",
      "---\n",
      "Confusion Matrix\n",
      "[[477 146  90  54]\n",
      " [182 358  54  48]\n",
      " [104  57  37  18]\n",
      " [ 98  84  31  61]]\n",
      "---\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.62      0.59       767\n",
      "           1       0.56      0.56      0.56       642\n",
      "           2       0.17      0.17      0.17       216\n",
      "           3       0.34      0.22      0.27       274\n",
      "\n",
      "   micro avg       0.49      0.49      0.49      1899\n",
      "   macro avg       0.41      0.39      0.40      1899\n",
      "weighted avg       0.48      0.49      0.48      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_eval(Xtest, ytest, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "putTestValue(\"../database/TASS/TASS2018/task1-Test.xml\", \"output2018-3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = [\"2.0k\", \"2.5k\", \"3.0k\", \"3.5k\", \"4.0k\", \"all\"]\n",
    "# xs = [10000, 20000, 30000, 40000, 50000, 64170, 64450]\n",
    "# we have changed the actual numbers to evenly space the points\n",
    "xs = [2000, 2500, 3000, 3500, 4000, 4344]\n",
    "\n",
    "ylabels = [\"BoW/NB\", \"BoW/SVM\", \"SIF/NB\", \"SIF/SVM\"]\n",
    "ys = np.array(\n",
    "        [[0.627, 0.635, 0.635, 0.632, 0.635, 0.648],\n",
    "         [0.733, 0.744, 0.755, 0.747, 0.755, 0.747],\n",
    "         [0.587, 0.600, 0.605, 0.635, 0.648, 0.648],\n",
    "         [0.728, 0.725, 0.736, 0.731, 0.736, 0.741]])\n",
    "ids_nb = [i for i, y in enumerate(ylabels) if y.endswith(\"/NB\")]\n",
    "labels_nb = [y.split(\"/\")[0] for y in ylabels if y.endswith(\"/NB\")]\n",
    "ids_svm = [i for i, y in enumerate(ylabels) if y.endswith(\"/SVM\")]\n",
    "labels_svm = [y.split(\"/\")[0] for y in ylabels if y.endswith(\"/SVM\")]\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "curr_row = 0\n",
    "for row in ids_nb:\n",
    "    plt.plot(xs, ys[row, :], marker=\"o\", \n",
    "             color=colors[curr_row], label=labels_nb[curr_row])\n",
    "    curr_row += 1\n",
    "plt.xticks(xs, xlabels)\n",
    "plt.title(\"Naive Bayes (TASS 2017)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.xlabel(\"vocab size\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(122)\n",
    "curr_row = 0\n",
    "for row in ids_svm:\n",
    "    plt.plot(xs, ys[row, :], marker=\"o\", \n",
    "             color=colors[curr_row], label=labels_svm[curr_row])\n",
    "    curr_row += 1\n",
    "plt.xticks(xs, xlabels)\n",
    "plt.title(\"Support Vector Machine C=0.8 (TASS 2017)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.xlabel(\"vocab size\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabels = [\"1.0k\", \"1.5k\", \"2.0k\", \"2.5k\", \"3.0k\", \"all\"]\n",
    "# xs = [10000, 20000, 30000, 40000, 50000, 64170, 64450]\n",
    "# we have changed the actual numbers to evenly space the points\n",
    "xs = [1000, 1500, 2000, 2500, 3000, 3142]\n",
    "\n",
    "ylabels = [\"BoW/NB\", \"BoW/SVM\", \"SIF/NB\", \"SIF/SVM\"]\n",
    "ys = np.array(\n",
    "        [[0.537, 0.552, 0.562, 0.557, 0.562, 0.562],\n",
    "         [0.686, 0.726, 0.726, 0.706, 0.711, 0.736],\n",
    "         [0.517, 0.532, 0.552, 0.562, 0.572, 0.592],\n",
    "         [0.696, 0.686, 0.686, 0.701, 0.691, 0.716]])\n",
    "ids_nb = [i for i, y in enumerate(ylabels) if y.endswith(\"/NB\")]\n",
    "labels_nb = [y.split(\"/\")[0] for y in ylabels if y.endswith(\"/NB\")]\n",
    "ids_svm = [i for i, y in enumerate(ylabels) if y.endswith(\"/SVM\")]\n",
    "labels_svm = [y.split(\"/\")[0] for y in ylabels if y.endswith(\"/SVM\")]\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(121)\n",
    "curr_row = 0\n",
    "for row in ids_nb:\n",
    "    plt.plot(xs, ys[row, :], marker=\"o\", \n",
    "             color=colors[curr_row], label=labels_nb[curr_row])\n",
    "    curr_row += 1\n",
    "plt.xticks(xs, xlabels)\n",
    "plt.title(\"Naive Bayes (TASS 2018)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.xlabel(\"vocab size\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.subplot(122)\n",
    "curr_row = 0\n",
    "for row in ids_svm:\n",
    "    plt.plot(xs, ys[row, :], marker=\"o\", \n",
    "             color=colors[curr_row], label=labels_svm[curr_row])\n",
    "    curr_row += 1\n",
    "plt.xticks(xs, xlabels)\n",
    "plt.title(\"Support Vector Machine C=10 (TASS 2018)\")\n",
    "plt.ylabel(\"classification accuracy\")\n",
    "plt.xlabel(\"vocab size\")\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tflearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "from tflearn.data_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network building\n",
    "def build_model():\n",
    "    # This resets all parameters and variables, leave this here\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    # Inputs\n",
    "    net = tflearn.input_data([None, 45])\n",
    "\n",
    "    # Hidden layer(s)\n",
    "    net = tflearn.fully_connected(net, 300, activation='ReLU')\n",
    "    #net = tflearn.dropout(net, keep_prob=0.2)\n",
    "    net = tflearn.fully_connected(net, 150, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 50, activation='ReLU')\n",
    "    net = tflearn.fully_connected(net, 10, activation='ReLU')\n",
    "\n",
    "    # Output layer\n",
    "    net = tflearn.fully_connected(net, 4, activation='sigmoid')\n",
    "    net = tflearn.regression(net, optimizer='sgd', \n",
    "                             learning_rate=0.5, \n",
    "                             loss='categorical_crossentropy')\n",
    "    \n",
    "    model = tflearn.DNN(net)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for tweet in corpus:\n",
    "    sentence = []\n",
    "    for word in ut.tokenizer(tweet):\n",
    "        try:\n",
    "            i = counter.vocabulary_[word]\n",
    "            sentence.append(i)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        \n",
    "    sequences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "x_train_seq = pad_sequences(sequences[:len(Xtrain)], maxlen=45)\n",
    "x_test_seq  = pad_sequences(sequences[-len(Xtest):], maxlen=45)\n",
    "print('Shape of data train tensor:', x_train_seq.shape)\n",
    "print('Shape of data val  tensor:', x_test_seq.shape)\n",
    "print(len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train_seq, ytrain, validation_set=0.2, show_metric=True, batch_size=64, n_epoch=150)\n",
    "model.fit(x_train_seq, to_categorical(ytrain, 4), validation_set=0.2, show_metric=True, batch_size=64, n_epoch=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "def test_eval(Xtest, ytest, clf):\n",
    "    print(\"===\")\n",
    "    print(\"Test set results\")\n",
    "    ytest_ = argmax(clf.predict(Xtest), axis=1)\n",
    "    accuracy = accuracy_score(ytest, ytest_)\n",
    "    acc.append(accuracy)\n",
    "    print(\"Accuracy: {:.3f}\".format(accuracy))\n",
    "    print(\"---\")\n",
    "    print(\"Confusion Matrix\")\n",
    "    cm = confusion_matrix(ytest, ytest_)\n",
    "    print(cm)\n",
    "    print(\"---\")\n",
    "    print(\"Classification Report\")\n",
    "    cr = classification_report(ytest, ytest_)\n",
    "    print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval(x_test_seq, ytest, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "from utils import data\n",
    "from models.gru_svm.gru_svm import GruSvm\n",
    "\n",
    "# hyper-parameters for the model\n",
    "BATCH_SIZE = 256\n",
    "CELL_SIZE = 256\n",
    "DROPOUT_P_KEEP = 0.85\n",
    "HM_EPOCHS = 10\n",
    "LEARNING_RATE = 1e-5\n",
    "N_CLASSES = 2\n",
    "SEQUENCE_LENGTH = 21\n",
    "SVM_C = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "\n",
    "    if argv.operation == 'train':\n",
    "        # get the train data\n",
    "        # features: train_data[0], labels: train_data[1]\n",
    "        train_features, train_labels = data.load_data(dataset=argv.train_dataset)\n",
    "\n",
    "        # get the validation data\n",
    "        # features: validation_data[0], labels: validation_data[1]\n",
    "        validation_features, validation_labels = data.load_data(dataset=argv.validation_dataset)\n",
    "\n",
    "        # get the size of the dataset for slicing\n",
    "        train_size = train_features.shape[0]\n",
    "        validation_size = validation_features.shape[0]\n",
    "\n",
    "        # slice the dataset to be exact as per the batch size\n",
    "        # e.g. train_size = 1898322, batch_size = 256\n",
    "        # [:1898322-(1898322%256)] = [:1898240]\n",
    "        # 1898322 // 256 = 7415; 7415 * 256 = 1898240\n",
    "        train_features = train_features[:train_size-(train_size % BATCH_SIZE)]\n",
    "        train_labels = train_labels[:train_size-(train_size % BATCH_SIZE)]\n",
    "\n",
    "        # modify the size of the dataset to be passed on model.train()\n",
    "        train_size = train_features.shape[0]\n",
    "\n",
    "        # slice the dataset to be exact as per the batch size\n",
    "        validation_features = validation_features[:validation_size-(validation_size % BATCH_SIZE)]\n",
    "        validation_labels = validation_labels[:validation_size-(validation_size % BATCH_SIZE)]\n",
    "\n",
    "        # modify the size of the dataset to be passed on model.train()\n",
    "        validation_size = validation_features.shape[0]\n",
    "\n",
    "        # instantiate the model\n",
    "        model = GruSvm(alpha=LEARNING_RATE, batch_size=BATCH_SIZE, cell_size=CELL_SIZE, dropout_rate=DROPOUT_P_KEEP,\n",
    "                       num_classes=N_CLASSES, sequence_length=SEQUENCE_LENGTH, svm_c=SVM_C)\n",
    "\n",
    "        # train the model\n",
    "        model.train(checkpoint_path=argv.checkpoint_path, log_path=argv.log_path, model_name=argv.model_name,\n",
    "                    epochs=HM_EPOCHS, train_data=[train_features, train_labels], train_size=train_size,\n",
    "                    validation_data=[validation_features, validation_labels], validation_size=validation_size,\n",
    "                    result_path=argv.result_path)\n",
    "    elif argv.operation == 'test':\n",
    "        test_features, test_labels = data.load_data(dataset=argv.validation_dataset)\n",
    "\n",
    "        test_size = test_features.shape[0]\n",
    "\n",
    "        test_features = test_features[:test_size-(test_size % BATCH_SIZE)]\n",
    "        test_labels = test_labels[:test_size-(test_size % BATCH_SIZE)]\n",
    "\n",
    "        test_size = test_features.shape[0]\n",
    "\n",
    "        GruSvm.predict(batch_size=BATCH_SIZE, cell_size=CELL_SIZE, dropout_rate=DROPOUT_P_KEEP, num_classes=N_CLASSES,\n",
    "                       test_data=[test_features, test_labels], test_size=test_size,\n",
    "checkpoint_path=argv.checkpoint_path, result_path=argv.result_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
